{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clustering Conformations using Python Libraries\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dependencies"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, leaves_list, to_tree, centroid, cut_tree,fcluster\n",
    "from matplotlib import pyplot as plt\n",
    "from helper import info, threshold_remove, multirun\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Isolate lists with missing residues beyond a threshold\n",
    "\n",
    "#### threshold_remove(threshold, segments = None)\n",
    "Parameters: threshold, maximum number of missing residues before discarded\n",
    "Segments, default None analyzes the complete sequence for missing residues.\n",
    "Otherwise takes in a list of tuples (start, end) residue indices using zero indexing.\n",
    "\n",
    "This method is for the purpose of threshold vs missclassification analysis. In this case the full length is kept since the whole chains_list will be analyzed regardless of the amount of missing indices."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "threshold_remove(298)\n",
    "threshold_remove(298,[(32,43),(149,158)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load presorted classification based on annotations list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#@ open files\n",
    "with open(\"chains_list.var\",\"rb\") as chains_list_var:\n",
    "   chains_list = pickle.load(chains_list_var)\n",
    "   chains_list_var.close()\n",
    "#print(f\"chains_list: {chains_list}\")\n",
    "with open(\"structures/opened_active.var\", \"rb\") as open_active_var:\n",
    "    open_active_list = pickle.load(open_active_var)\n",
    "    open_active_var.close()\n",
    "with open(\"structures/closed_inactive.var\", \"rb\") as closed_inactive_var:\n",
    "    closed_inactive_list = pickle.load(closed_inactive_var)\n",
    "    closed_inactive_var.close()\n",
    "with open(\"structures/opened_inactive.var\", \"rb\") as open_inactive_var:\n",
    "    open_inactive_list = pickle.load(open_inactive_var)\n",
    "    open_inactive_var.close()\n",
    "\n",
    "print(f\"open_active: {len(open_active_list)}\")\n",
    "print(f\"closed_inactive: {len(closed_inactive_list)}\")\n",
    "print(f\"open_inactive: {len(open_inactive_list)}\")\n",
    "annotated_dict_list_codes= {\"open_active\": open_active_list, \"closed_inactive\": closed_inactive_list, \"open_inactive\": open_inactive_list} #dictionary of codes list\n",
    "annotated_dict_list ={\"open_active\": list(), \"closed_inactive\": list(), \"open_inactive\": list()} #dictionary of list of indices\n",
    "for i,conformation in enumerate(chains_list):\n",
    "    for j,l in enumerate(annotated_dict_list_codes):\n",
    "        if conformation in annotated_dict_list_codes[l]:\n",
    "            #print(f\"l: {l}\")\n",
    "            annotated_dict_list[l].append(i)\n",
    "#print(f\"annotated_dict_list: {annotated_dict_list_codes}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "open_active: 162\n",
      "closed_inactive: 277\n",
      "open_inactive: 92\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Open calculated rms matrix and chains list\n",
    "#### matrix.var\n",
    "Calculated rms matrix from aligning all of the choice conformation chosen by best_align.py and calculated by pml_script_all.py.\n",
    "#### chains_list.var\n",
    "Generated by reading through the dictionary of annotated conformations and making a list of chains of the conformation. This will give the labeling order of the rms matrix obtained since pml_script_all.py iterated through this list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(\"matrix.var\", \"rb\") as matrix_var:\n",
    "   matrix = (pickle.load(matrix_var))\n",
    "   matrix_var.close()\n",
    "#print(f\"matrix: {matrix}\")\n",
    "with open(\"matrix_AB.var\", \"rb\") as matrix_AB_var:\n",
    "   matrix_AB = (pickle.load(matrix_AB_var))\n",
    "   matrix_AB_var.close()\n",
    "with open(\"matrix_seg.var\", \"rb\") as matrix_seg_var:\n",
    "   matrix_seg = pickle.load(matrix_seg_var)\n",
    "   matrix_seg_var.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ward's Algorithm\n",
    "A linkage with minimum variance method. We define \n",
    "$$\n",
    "T = |v| + |s| + |t|\n",
    "$$\n",
    "As the cardinality the forest _u_ and _v_ combined\n",
    "Given the distance function is computed recursively with the equation:\n",
    "$$\n",
    "d[i][j] = d(i,j) = \\sqrt{\\frac{|v| + |s|}{T}d(v,s)^2 + \\frac{|v| + |t|}{T}d(v,t)^2 - \\frac{|v|}{T}d(s,t)^2}\n",
    "$$\n",
    "The merging cost, of which ward's algorithm tries to minimize the growth is defined as follows:\n",
    "$$\n",
    "Cost(u,v) = \\frac{|u||v|}{|u| +|v|}||c_u - c_v ||^2\n",
    "$$\n",
    "$c_i$ is the vector of the centroid. And the derivation comes from the distance sum union of the two sets together minus the distance sum of the individual sets. \n",
    "<br>\n",
    "It considers the case of merging and then calculates the variance from the centroid of the final merged cluster as the distance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Info function:\n",
    " ```info(matrix,title,chains_list,annotated_dict_list,complete,kernel=\"linear\",hierarchy_method = None, no_clusters=3, dist_metric = \"euclidean\", tsne= False, auto_cut_tree = True)```\n",
    "### Usage:\n",
    "### __Required Parameters__:\n",
    "#### matrix:\n",
    "    A matrix of values where each row represents a conformation and the features along the columns\n",
    "    In this case we have RMSD of all the CA, RMSD of all CA + CB, RSMD of all CA of specific segments\n",
    "#### title: \n",
    "    Title of the matrix for plotting purposes\n",
    "#### chains_list:\n",
    "    List chains/ conformations in the same order as the matrix\n",
    "#### annotated_dict_list:\n",
    "    Dictionary where each key is group classified, found by pdb file annotation and value is a list of indices of the conformations on the matrix\n",
    "#### complete:\n",
    "    For the purposes of identifying the coincidence of misclassification and missing residues beyond a certain threshold. Complete is a boolean, if True it will compare the coincidences to the full conformation based threshold reduce file. Else false it will compare to the conformation on specific segments based threshold reduced file.\n",
    "### __Optional Parameters__:\n",
    "#### kernel:\n",
    "    For the use of PCA, Kernel method of PCA (if in use)\n",
    "#### Hierarchy_method:\n",
    "    Method of hierachical clustering, default is None. set to None then the function will use the graph for Kmeans clustering by default. Uses sklearn and scipy hierarchy clustering. \n",
    "    Choices: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’, ‘precomputed’}\n",
    "#### no_clusters:\n",
    "    Number of clusters to be found. However, the statistics will give an error if the amount of clusters and the length of the ```annotated_dict_list``` do not match\n",
    "#### dist_metric:\n",
    "    Distance metric for hierarchical clustering, by default euclidean\n",
    "#### tsne:\n",
    "    Data is visualized in 2 different ways T-SNE and PCA, By default tsne = False means PCA is used. Data is projected into 2 dimensions\n",
    "#### auto_cut_tree:\n",
    "    By default the tree will be automatically cut by the number of clusters, however, if set to False, manual cutting will ask the user to get left or right tree in a sequence from top down.\n",
    "    The first choice will prompt the user for the leftmost tree and then the second choice for the middle tree.\n",
    "    Use the calculated dendrogram to decide on the manual tree partitioning.\n",
    "    Use: \"left\", \"l\", \"right\", or \"r\"\n",
    "    The statistics will give an erroneous result if the middle tree, the second tree is chosen not to the immediate right of the first tree.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 1:\n",
    "Complete CA, T-SNE projection with Ward's algorithm to obtain 3 clusters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "info(matrix,\"Complete CA\", chains_list,annotated_dict_list, complete= True, kernel=\"linear\",hierarchy_method = \"ward\", no_clusters=3,tsne=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/yao/Desktop/dkp/Work/internship1_bioinfo/helper.py:549: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  out = linkage(matrix, method = hierarchy_method, metric = dist_metric)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment 2:\n",
    "Complete CA, PCA projection with Ward's algorithm to obtain 3 clusters.\n",
    "### Analysis:\n",
    "The data shows that open inactive is often misrepresented as closed in active 96 False negative and only 16 True positive, also T-sne gives a better cluster view of the data than PCA, which shades clusters as less distinct."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info(matrix,\"Complete CA\", chains_list,annotated_dict_list,complete = True, kernel=\"linear\",hierarchy_method = \"ward\", no_clusters=3,tsne=False)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/yao/.vscode/extensions/ms-toolsai.jupyter-2021.8.1195043623/out/client/extension.js:90:325139)",
      "at w.execute (/Users/yao/.vscode/extensions/ms-toolsai.jupyter-2021.8.1195043623/out/client/extension.js:90:324460)",
      "at w.start (/Users/yao/.vscode/extensions/ms-toolsai.jupyter-2021.8.1195043623/out/client/extension.js:90:320276)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/yao/.vscode/extensions/ms-toolsai.jupyter-2021.8.1195043623/out/client/extension.js:90:334803)",
      "at async t.CellExecutionQueue.start (/Users/yao/.vscode/extensions/ms-toolsai.jupyter-2021.8.1195043623/out/client/extension.js:90:334343)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 3\n",
    "Complete CA and CB RSMD Matrix, T-SNE projection with Ward's algorithm to obtain 3 clusters.\n",
    "### Analysis:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info(matrix_AB,\"Complete CA and CB\", chains_list,annotated_dict_list,complete = True,kernel=\"linear\",hierarchy_method = \"ward\", no_clusters=3,tsne=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 4\n",
    "Complete CA and CB RSMD Matrix, PCA projection with Ward's algorithm to obtain 3 clusters.\n",
    "### Analysis:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info(matrix_AB,\"Complete CA and CB\", chains_list,annotated_dict_list,complete = True,kernel=\"linear\",hierarchy_method = \"ward\", no_clusters=3,tsne=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 5\n",
    "Selected Segments 33 to 44, 150 to 159, found from previous pymol modelling analysis. RSMD Matrix, T-SNE projection with Ward's algorithm to obtain 3 clusters.\n",
    "\n",
    "### Analysis:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info(matrix_seg,\"Complete CA and CB\", chains_list,annotated_dict_list,complete = True,kernel=\"linear\",hierarchy_method = \"ward\", no_clusters=3,tsne=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 6\n",
    "Selected Segments 33 to 44, 150 to 159, found from previous pymol modelling analysis. T-SNE projection with Ward's algorithm to obtain 3 clusters, Manual Tree parititioning, Cluster1 = Tree.left.left, Cluster2 = Tree.left.right, Cluster3 = Tree.right\n",
    "### Analysis:\n",
    "This gives quite a high F1 score, however the partitioning is not as intuitive since Cluster 1 and Cluster 2 are highly similar and have low cophenetic distances compared to the Cluster 3. Maybe a change of distance metric might give different clustering results.\n",
    "\n",
    "Actually, running a script to check how many chains are missing more than 7 residues in on of the segments (keeping in mind that the segments are only 12 and 10 residues long). The script outputs 176 samples. This is more than the amount misclassified at 79 conformations.\n",
    "\n",
    "Taking from the misclassified examples 2BHH_A on the top right of the graph of the misclassified conformation has a gap from residue 36 to 43 and 148 to 162 which given only two residues of course would have trouble identifying the clustering.\n",
    "1AQ1_A missing from 36 to 44 and 148 to 160.\n",
    "\n",
    "On the other side of the misclassified cluster, 2AOC_X has only missing 37-40, 4 key residues missing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "info(matrix_seg,\"Complete CA and CB\", chains_list,annotated_dict_list,complete = True,hierarchy_method = \"ward\", no_clusters=3,tsne=True,auto_cut_tree=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multi run on the full chain without threshold:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "multirun(annotated_dict_list,threshold=298, segments=None,iter=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Threshold: 7 amount removed: 250\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rf/gvtptwp96wvd1g29v6rqbgj40000gn/T/ipykernel_13057/2851655202.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmultirun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_dict_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/dkp/Work/internship1_bioinfo/helper.py\u001b[0m in \u001b[0;36mmultirun\u001b[0;34m(annotated_dict_list, segments, threshold, no_clusters, iter)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0mnew_seg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreshold_remove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seg_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannotated_dict_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_clusters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_stats_process\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mfinal_averages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Iterations: {iter}, f1_avg: {final_averages[0,0]}, p_avg: {final_averages[0,1]}, r_avg: {final_averages[0,2]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dkp/Work/internship1_bioinfo/helper.py\u001b[0m in \u001b[0;36mcalc_stats_process\u001b[0;34m(triple)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0mnew_seg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotated_dict_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m     \u001b[0mconformation_by_seg_by_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_impute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_seg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mseg_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconformation_by_seg_by_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;31m#thread = threading.Thread(target = pause_and_print, args= (f\"matrix: {type(matrix)}\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/dkp/Work/internship1_bioinfo/helper.py\u001b[0m in \u001b[0;36mcoordinate_impute\u001b[0;34m(seg_list)\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0mresidue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m#print(f\"temp[i]: {temp[i]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}